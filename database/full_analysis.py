# å®Œæ•´åˆ†æï¼šæª¢æŸ¥æ¯å€‹ INSERT ä¸­æ‰€æœ‰å€åŸŸçš„åˆ†ä½ˆ
# åŸ·è¡Œ: python full_analysis.py

from pathlib import Path
import re
from collections import defaultdict

SQL_PATH = "houseDatabase_version_1.sql"

def split_value_tuples(block: str) -> list:
    """åˆ‡åˆ† value tuples"""
    parts, buf, level, in_str, esc = [], [], 0, False, False
    for ch in block:
        if esc:
            buf.append(ch); esc=False; continue
        if ch == "\\":
            buf.append(ch); esc=True; continue
        if ch == "'" and not esc:
            in_str = not in_str; buf.append(ch); continue
        if not in_str:
            if ch == "(": level += 1
            if ch == ")": level -= 1
        buf.append(ch)
        if level == 0 and ch == ")":
            t = "".join(buf).strip()
            if not t.startswith("("): t = "(" + t
            if not t.endswith(")"):  t = t + ")"
            parts.append(t); buf=[]
    return parts

def parse_tuple_text(tup: str) -> list:
    """è§£æå–®å€‹ tuple"""
    t = tup.strip()
    if not t.startswith("("): t = "(" + t
    if not t.endswith(")"):  t = t + ")"
    s = t[1:-1]
    fields, tok, in_str, esc, level = [], [], False, False, 0
    for ch in s:
        if esc: tok.append(ch); esc=False; continue
        if ch == "\\": tok.append(ch); esc=True; continue
        if ch == "'" and level == 0:
            in_str = not in_str; tok.append(ch); continue
        if not in_str:
            if ch == "(": level += 1; tok.append(ch); continue
            if ch == ")": level -= 1; tok.append(ch); continue
            if ch == "," and level == 0:
                fields.append("".join(tok).strip()); tok=[]; continue
        tok.append(ch)
    if tok: fields.append("".join(tok).strip())
    return fields

def full_analysis(sql_path: str):
    """å®Œæ•´åˆ†ææ¯å€‹ INSERT ä¸­çš„æ‰€æœ‰è³‡æ–™"""
    text = Path(sql_path).read_text(encoding="utf-8", errors="ignore")
    
    pattern = re.compile(
        r"INSERT\s+INTO\s+`?houses`?\s+VALUES\s*(.+?);",
        flags=re.IGNORECASE | re.DOTALL
    )
    
    print("=" * 80)
    print("ğŸ” å®Œæ•´åˆ†æï¼šæª¢æŸ¥æ¯å€‹ INSERT çš„æ‰€æœ‰å€åŸŸ")
    print("=" * 80)
    
    matches = pattern.findall(text)
    insert_districts = []  # æ¯å€‹ INSERT çš„å€åŸŸçµ±è¨ˆ
    all_districts = defaultdict(int)
    total_rows = 0
    failed_count = 0
    
    for idx, values_blob in enumerate(matches):
        print(f"\nğŸ“ åˆ†æ INSERT #{idx + 1}...")
        
        tuples = split_value_tuples(values_blob)
        print(f"   ç¸½å…± {len(tuples):,} å€‹ tuples")
        
        district_count = defaultdict(int)
        success = 0
        
        # è§£æé€™å€‹ INSERT ä¸­çš„æ‰€æœ‰ tuples
        for i, tup in enumerate(tuples):
            try:
                fields = parse_tuple_text(tup)
                if len(fields) >= 5:
                    district = fields[4].strip().strip("'")
                    district_count[district] += 1
                    all_districts[district] += 1
                    success += 1
            except Exception as e:
                failed_count += 1
                if failed_count <= 3:  # åªé¡¯ç¤ºå‰3å€‹éŒ¯èª¤
                    print(f"   âš ï¸ ç¬¬ {i+1} å€‹ tuple å¤±æ•—: {str(e)[:50]}")
        
        total_rows += success
        print(f"   âœ… æˆåŠŸ: {success:,}/{len(tuples):,} ({success/len(tuples)*100:.1f}%)")
        print(f"   ğŸ“Š åŒ…å« {len(district_count)} å€‹ä¸åŒå€åŸŸ:")
        
        # é¡¯ç¤ºé€™å€‹ INSERT çš„å€åŸŸåˆ†ä½ˆ
        for district, count in sorted(district_count.items(), key=lambda x: -x[1])[:5]:
            print(f"      â€¢ {district}: {count:,} ç­†")
        if len(district_count) > 5:
            print(f"      ... é‚„æœ‰ {len(district_count) - 5} å€‹å€åŸŸ")
        
        insert_districts.append({
            "insert_num": idx + 1,
            "total_tuples": len(tuples),
            "success": success,
            "districts": dict(district_count)
        })
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ç¸½é«”çµ±è¨ˆ")
    print("=" * 80)
    print(f"\nç¸½ INSERT æ•¸: {len(matches)}")
    print(f"ç¸½æˆåŠŸè§£æ: {total_rows:,} ç­†")
    print(f"ç¸½å¤±æ•—: {failed_count:,} ç­†")
    print(f"\nç™¼ç¾çš„æ‰€æœ‰å€åŸŸ ({len(all_districts)} å€‹):")
    
    for district, count in sorted(all_districts.items(), key=lambda x: -x[1]):
        print(f"  â€¢ {district}: {count:,} ç­†")
    
    # æ–°åŒ—å¸‚29å€
    NEWTAIPEI_29 = [
        "æ¿æ©‹å€","ä¸‰é‡å€","ä¸­å’Œå€","æ°¸å’Œå€","æ–°èŠå€","æ–°åº—å€","æ¨¹æ—å€","é¶¯æ­Œå€","ä¸‰å³½å€",
        "æ·¡æ°´å€","æ±æ­¢å€","ç‘èŠ³å€","åœŸåŸå€","è˜†æ´²å€","äº”è‚¡å€","æ³°å±±å€","æ—å£å€","æ·±å‘å€",
        "çŸ³ç¢‡å€","åªæ—å€","ä¸‰èŠå€","çŸ³é–€å€","å…«é‡Œå€","å¹³æºªå€","é›™æºªå€","è²¢å¯®å€","é‡‘å±±å€",
        "è¬é‡Œå€","çƒä¾†å€"
    ]
    
    missing = [d for d in NEWTAIPEI_29 if d not in all_districts]
    
    print(f"\nâœ… æ–°åŒ—å¸‚29å€è¦†è“‹ç‡: {29 - len(missing)}/29")
    if missing:
        print(f"âŒ ç¼ºå°‘çš„å€åŸŸ ({len(missing)} å€‹):")
        for d in missing:
            print(f"  â€¢ {d}")
    else:
        print("ğŸ‰ æ‰€æœ‰29å€éƒ½æœ‰è³‡æ–™ï¼")
    
    return insert_districts, all_districts

if __name__ == "__main__":
    insert_info, district_stats = full_analysis(SQL_PATH)
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ çµè«–")
    print("=" * 80)
    
    if len(district_stats) == 29:
        print("\nâœ… SQL æª”æ¡ˆåŒ…å«å®Œæ•´çš„æ–°åŒ—å¸‚29å€è³‡æ–™")
        print("âœ… ä½ çš„ app.py è§£æé‚è¼¯æ‡‰è©²æ˜¯æ­£ç¢ºçš„")
        print("\nğŸ” å¦‚æœ /health API åªé¡¯ç¤º15å€‹å€ï¼Œå¯èƒ½æ˜¯:")
        print("   1. pandas DataFrame åˆä½µ/å»é‡æ™‚å‡ºäº†å•é¡Œ")
        print("   2. _normalize_admin() å‡½æ•¸æŠŠæŸäº›å€åŸŸæ­£è¦åŒ–éŒ¯äº†")
        print("   3. è³‡æ–™è¼‰å…¥æ™‚æŸäº› INSERT è¢«è·³éäº†")
        print("\nå»ºè­°ï¼šåœ¨ app.py çš„ _load_df_from_sql() åŠ ä¸Šæ›´å¤š debug è¼¸å‡º")
    else:
        print(f"\nâš ï¸ åªè§£æå‡º {len(district_stats)} å€‹å€åŸŸ")
        print("éœ€è¦æª¢æŸ¥ tuple è§£æé‚è¼¯")